# ğŸ¬ Media Scraper

A high-performance web scraper for images and videos. Optimized for 1 CPU, 1GB RAM servers.

![Node.js](https://img.shields.io/badge/Node.js-20+-green)
![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue)
![Redis](https://img.shields.io/badge/Redis-7-red)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)

## âœ¨ Features

- **Smart Scraping** - Auto-selects Cheerio (static) or Puppeteer (JS-heavy)
- **Background Processing** - Bull queue handles 5000+ concurrent requests
- **2-Layer Deduplication** - Queue and cache-level URL filtering
- **Dead Letter Queue** - Structured logging for failed jobs
- **Memory Optimized** - GC hints, browser restart, connection pooling

## ğŸš€ Quick Start

```bash
# Start services
docker-compose up -d

# Setup database (run from backend folder)
cd backend
npm install
npm run db:push
npm run prisma:seed
```

**URLs:**
- Frontend: http://localhost:3000
- API: http://localhost:3001
- Health: http://localhost:3001/health

**Login:** `admin` / `admin123`

## ğŸ“– API Endpoints

All endpoints require Basic Auth except `/health`.

```bash
curl -u admin:admin123 http://localhost:3001/api/media
```

| Method | Endpoint                  | Description                    |
| ------ | ------------------------- | ------------------------------ |
| POST   | `/api/auth/login`         | Validate credentials           |
| GET    | `/api/auth/me`            | Get current user               |
| POST   | `/api/scrape`             | Submit URLs for scraping       |
| GET    | `/api/scrape/queue/stats` | Queue statistics               |
| GET    | `/api/jobs`               | List jobs (paginated)          |
| GET    | `/api/jobs/:id`           | Get job details                |
| GET    | `/api/media`              | List media (paginated, filter) |
| GET    | `/api/media/stats`        | Media statistics               |
| GET    | `/api/media/:id`          | Get media item                 |
| GET    | `/health`                 | Health check (no auth)         |

**Query params for `/api/media`:** `page`, `limit`, `type` (image/video), `search`

## ğŸ”§ Configuration

| Variable              | Default     | Description                  |
| --------------------- | ----------- | ---------------------------- |
| `DATABASE_URL`        | -           | PostgreSQL connection string |
| `REDIS_HOST`          | `localhost` | Redis host                   |
| `REDIS_PORT`          | `6379`      | Redis port                   |
| `SCRAPER_CONCURRENCY` | `3`         | Parallel scrape jobs         |
| `SCRAPER_TIMEOUT`     | `30000`     | Timeout in ms                |

For 1GB RAM, add to DATABASE_URL: `?connection_limit=5&pool_timeout=10`

## ğŸ“ Project Structure

```
momos/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/       # Environment, database, Redis
â”‚   â”‚   â”œâ”€â”€ middleware/   # Auth, validation, errors
â”‚   â”‚   â”œâ”€â”€ routes/       # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic
â”‚   â”‚   â”œâ”€â”€ scrapers/     # Cheerio & Puppeteer
â”‚   â”‚   â”œâ”€â”€ queue/        # Bull queue management
â”‚   â”‚   â””â”€â”€ utils/        # Memory, cache
â”‚   â””â”€â”€ prisma/           # Database schema & migrations
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # UI components
â”‚       â”œâ”€â”€ contexts/     # Auth context
â”‚       â”œâ”€â”€ lib/          # API client, hooks
â”‚       â””â”€â”€ pages/        # Page components
â””â”€â”€ docker-compose.yml
```

## ğŸ”„ Scraping Flow

```
POST /api/scrape â†’ Dedupe within request
        â†“
Queue Manager â†’ Skip: cached URLs, pending URLs
        â†“
Worker â†’ Check cache â†’ Scrape (Cheerio/Puppeteer) â†’ Save to DB
        â†“
On permanent failure â†’ Log to DLQ
```

## ğŸ“ˆ Optimizations

**Memory:** Puppeteer restart every 10 pages, GC hints, Prisma connection pooling

**Speed:** Redis-only caching, 2-layer deduplication, HTTP compression

**Reliability:** DLQ logging, retries with backoff, graceful shutdown

## ğŸ§ª Load Testing

```bash
cd backend
npm run load-test:quick   # 100 requests
npm run load-test         # ~5000 requests
npm run load-test:stress  # 5000 in 10 seconds
```

## ğŸ› Troubleshooting

```bash
# Check logs
docker-compose logs -f backend

# Check queue
curl -u admin:admin123 http://localhost:3001/api/scrape/queue/stats

# Check memory
curl http://localhost:3001/health/detailed

# View failed jobs
docker-compose logs backend | grep "\[DLQ\]"
```

## ğŸ› ï¸ Tech Stack

**Backend:** Express, TypeScript, Prisma, PostgreSQL, Bull/Redis, Cheerio, Puppeteer, Zod

**Frontend:** React 18, TypeScript, Vite, TanStack Query, Tailwind CSS, Axios

## ğŸ“„ License

MIT
